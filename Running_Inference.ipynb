{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "D1qUmP8sdPrH",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D1qUmP8sdPrH",
        "outputId": "fec67aee-e866-47a9-a715-393fd53c7ed2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b1994133-349a-4317-b508-19b0e4ac33a0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b1994133-349a-4317-b508-19b0e4ac33a0",
        "outputId": "bc7f33c5-e8be-4981-cd4a-3f726e6af782"
      },
      "outputs": [],
      "source": [
        "# Install libraries\n",
        "!pip install rioxarray sahi ultralytics geopandas shapely pillow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "97d39c2f",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Impoort libraries\n",
        "import numpy as np\n",
        "import rioxarray\n",
        "import geopandas as gpd\n",
        "from shapely.geometry import shape\n",
        "from shapely.ops import unary_union\n",
        "from rasterio.features import shapes\n",
        "from sahi import AutoDetectionModel\n",
        "from sahi.predict import get_sliced_prediction\n",
        "from PIL import Image\n",
        "import tempfile, os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a739dfe7",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Read GeoTIFF + Reproject to UTM\n",
        "def read_geotiff(tif_path):\n",
        "    xds = rioxarray.open_rasterio(tif_path)\n",
        "\n",
        "    # Band count validation\n",
        "    if xds.shape[0] < 3:\n",
        "        raise ValueError(f\"GeoTIFF only has {xds.shape[0]} bands, minimum 3 required\")\n",
        "\n",
        "    # Auto-detect UTM zone\n",
        "    center_lon = float((xds.x.min() + xds.x.max()) / 2)\n",
        "    center_lat = float((xds.y.min() + xds.y.max()) / 2)\n",
        "    zone = int((center_lon + 180) / 6) + 1\n",
        "    epsg = 32600 + zone if center_lat >= 0 else 32700 + zone\n",
        "    print(f\"Auto UTM: EPSG:{epsg}\")\n",
        "\n",
        "    # Reproject to UTM\n",
        "    xds_utm = xds.rio.reproject(f\"EPSG:{epsg}\")\n",
        "\n",
        "    meta = {\n",
        "        'transform': xds_utm.rio.transform(),\n",
        "        'crs': xds_utm.rio.crs,\n",
        "        'height': xds_utm.rio.height,\n",
        "        'width': xds_utm.rio.width,\n",
        "    }\n",
        "\n",
        "    # Convert to uint8\n",
        "    image = np.transpose(xds_utm.values[:3], (1, 2, 0))\n",
        "    if image.dtype != np.uint8:\n",
        "        image = ((image - image.min()) /\n",
        "                 (image.max() - image.min() + 1e-8) * 255).astype(np.uint8)\n",
        "\n",
        "    # Save tmp jpg\n",
        "    with tempfile.NamedTemporaryFile(suffix=\".jpg\", delete=False) as f:\n",
        "        tmp_path = f.name\n",
        "    Image.fromarray(image).save(tmp_path, quality=95)\n",
        "\n",
        "    return tmp_path, meta"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6e62d993",
      "metadata": {},
      "outputs": [],
      "source": [
        "# 2.Inference with SAHI\n",
        "def run_sahi(img_path, model_path, conf=0.25):\n",
        "    model = AutoDetectionModel.from_pretrained(\n",
        "        model_type=\"ultralytics\",\n",
        "        model_path=model_path,\n",
        "        confidence_threshold=conf,\n",
        "        device=\"cuda\",  # replace \"cpu\" if there is no GPU\n",
        "    )\n",
        "\n",
        "    result = get_sliced_prediction(\n",
        "        img_path, model,\n",
        "        slice_height=640, slice_width=640,\n",
        "        overlap_height_ratio=0.2, overlap_width_ratio=0.2,\n",
        "        perform_standard_pred=False,\n",
        "        postprocess_type=\"NMM\",\n",
        "        postprocess_match_threshold=0.5,\n",
        "        verbose=1,\n",
        "    )\n",
        "\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fba5c835",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Convert results to GeoJSON\n",
        "def predictions_to_geojson(result, meta, output_path=\"output/predictions.geojson\"):\n",
        "    records = []\n",
        "\n",
        "    for pred in result.object_prediction_list:\n",
        "        if pred.mask is None:\n",
        "            continue\n",
        "\n",
        "        bool_mask = pred.mask.bool_mask.astype(np.uint8)\n",
        "\n",
        "        for geom, val in shapes(bool_mask, mask=bool_mask, transform=meta['transform']):\n",
        "            if val == 0:\n",
        "                continue\n",
        "            records.append({\n",
        "                'geometry': shape(geom),\n",
        "                'class': pred.category.name,\n",
        "                'confidence': round(pred.score.value, 4)\n",
        "            })\n",
        "\n",
        "    if not records:\n",
        "        print(\"No objects detected\")\n",
        "        return gpd.GeoDataFrame()\n",
        "\n",
        "    gdf = gpd.GeoDataFrame(records, crs=meta['crs'])\n",
        "    gdf['area_m2'] = gdf.geometry.area.round(2)\n",
        "\n",
        "    output_dir = os.path.dirname(output_path)\n",
        "    if output_dir:\n",
        "        os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    gdf.to_file(output_path, driver=\"GeoJSON\")\n",
        "    print(f\"Save: {output_path} | Total objects: {len(gdf)}\")\n",
        "\n",
        "    return gdf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cd684f7b",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Running Infrance\n",
        "tmp_path, meta = read_geotiff(\"input.tif\")\n",
        "try:\n",
        "    result = run_sahi(tmp_path, \"best.pt\", conf=0.25)\n",
        "    gdf = predictions_to_geojson(result, meta, \"output/predictions.geojson\")\n",
        "finally:\n",
        "    os.remove(tmp_path) \n",
        "\n",
        "# Summery\n",
        "if not gdf.empty:\n",
        "    print(gdf.groupby('class')['area_m2'].agg(['count', 'sum', 'mean']).round(2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "19f4cb7e",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Post Processing\n",
        "def postprocess_geojson(input_path, output_path,\n",
        "                         min_area_m2=150,      # delete polygon 150 <  m²\n",
        "                         buffer_dist=1.0):      # merge distance in meters\n",
        "\n",
        "    gdf = gpd.read_file(input_path)\n",
        "\n",
        "    # Remove very small fragments\n",
        "    gdf = gdf[gdf['area_m2'] >= min_area_m2].copy()\n",
        "    print(f\"Setelah filter kecil: {len(gdf)} objek\")\n",
        "\n",
        "    # Small buffer → adjacent merge → reverse buffer\n",
        "    gdf['geometry'] = gdf.geometry.buffer(buffer_dist)   # expand\n",
        "    gdf['geometry'] = gdf.geometry.buffer(-buffer_dist)  # shrink balik\n",
        "\n",
        "    # Dissolve overlapping/touching polygons\n",
        "    gdf_dissolved = gdf.dissolve(by='class').reset_index()\n",
        "\n",
        "    # Break it back into individual polygons (explode multipolygon)\n",
        "    gdf_dissolved = gdf_dissolved.explode(index_parts=False).reset_index(drop=True)\n",
        "\n",
        "    # Recalculate the area after dissolving\n",
        "    gdf_dissolved['area_m2'] = gdf_dissolved.geometry.area.round(2)\n",
        "\n",
        "    # Filter again after dissolving\n",
        "    gdf_dissolved = gdf_dissolved[gdf_dissolved['area_m2'] >= min_area_m2]\n",
        "\n",
        "    gdf_dissolved.to_file(output_path, driver=\"GeoJSON\")\n",
        "    print(f\"✅ Done: {len(gdf_dissolved)} objec → {output_path}\")\n",
        "\n",
        "    return gdf_dissolved\n",
        "\n",
        "# Running\n",
        "gdf_clean = postprocess_geojson(\n",
        "    input_path=\"/content/output/predictions.geojson\",\n",
        "    output_path=\"/content/drive/MyDrive/yolo/crop_map.v5i.yolov11/infrance/predictions_clean.geojson\",\n",
        "    min_area_m2=150,    # adjust — minimum valid rice field area\n",
        "    buffer_dist=1.0     # adjust — the bigger the more aggressive the merge\n",
        ")\n",
        "\n",
        "print(gdf_clean[['class', 'area_m2']].describe().round(2))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
